{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOjII8X5TjDLphldJ0AC7Ee"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abs2nPOpP-NL",
        "outputId": "e05a3a67-5509-4233-d291-f3c36a0f27b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the pixel values of the images\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "metadata": {
        "id": "xQOsLVmUQMvI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the images to add a channel dimension\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.reshape(x_test.shape + (1,))"
      ],
      "metadata": {
        "id": "_Mw58wOdQOyx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the labels to one-hot encoded vectors\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)"
      ],
      "metadata": {
        "id": "FcXT_SQcQRVW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape of the images\n",
        "input_shape = (28, 28, 1)"
      ],
      "metadata": {
        "id": "U5TkeFP6QTh-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sequential model\n",
        "model = Sequential()"
      ],
      "metadata": {
        "id": "geJEPop3QVcR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add convolutional layers with max pooling and dropout\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))"
      ],
      "metadata": {
        "id": "ksSFje00QXcs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the output from convolutional layers\n",
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "uZ5usyUFQZvy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a fully connected layer with dropout\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))"
      ],
      "metadata": {
        "id": "CMIDyg7QQgJM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an output layer with 10 units and softmax activation\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "fXpf8d3mQihN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "kfVN8uJaQlHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25e2c379-7d32-4169-a341-1d55fc69ff3b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the MNIST dataset\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=20,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpioW_MVQnN3",
        "outputId": "df80ef3b-0acc-4e05-cde4-95922170b4a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 12s 6ms/step - loss: 0.3695 - accuracy: 0.8842 - val_loss: 0.0695 - val_accuracy: 0.9784\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1211 - accuracy: 0.9641 - val_loss: 0.0445 - val_accuracy: 0.9846\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0927 - accuracy: 0.9722 - val_loss: 0.0359 - val_accuracy: 0.9877\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0761 - accuracy: 0.9780 - val_loss: 0.0318 - val_accuracy: 0.9895\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0666 - accuracy: 0.9792 - val_loss: 0.0272 - val_accuracy: 0.9912\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0600 - accuracy: 0.9819 - val_loss: 0.0247 - val_accuracy: 0.9916\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0539 - accuracy: 0.9832 - val_loss: 0.0254 - val_accuracy: 0.9908\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0514 - accuracy: 0.9844 - val_loss: 0.0229 - val_accuracy: 0.9919\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0477 - accuracy: 0.9853 - val_loss: 0.0218 - val_accuracy: 0.9931\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0431 - accuracy: 0.9864 - val_loss: 0.0205 - val_accuracy: 0.9925\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0405 - accuracy: 0.9872 - val_loss: 0.0228 - val_accuracy: 0.9923\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0384 - accuracy: 0.9885 - val_loss: 0.0210 - val_accuracy: 0.9930\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0366 - accuracy: 0.9885 - val_loss: 0.0199 - val_accuracy: 0.9937\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0340 - accuracy: 0.9896 - val_loss: 0.0214 - val_accuracy: 0.9933\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0340 - accuracy: 0.9896 - val_loss: 0.0197 - val_accuracy: 0.9935\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0315 - accuracy: 0.9904 - val_loss: 0.0226 - val_accuracy: 0.9927\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.0207 - val_accuracy: 0.9943\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 0.0194 - val_accuracy: 0.9941\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0209 - val_accuracy: 0.9937\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.0230 - val_accuracy: 0.9931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the testing set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqwdxLq1QpLT",
        "outputId": "4e16f1d2-1c15-4fa0-b98a-25d9e1b56ca7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.023016266524791718\n",
            "Test accuracy: 0.9930999875068665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **Conclusion:**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In this project, we built a machine learning model to recognize handwritten digits using the MNIST dataset. We preprocessed the data by normalizing and reshaping it, and used a convolutional neural network architecture to train the model. We achieved a high test accuracy of **99.31%**.\n",
        "\n",
        "Overall, this project demonstrates the power of machine learning in image recognition tasks. With further tuning and optimization, this model could potentially be used in various applications, such as digit recognition in check processing or postal mail sorting.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DonjD69vSm1C"
      }
    }
  ]
}